{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Финальный проект: предсказание победителя в игре Dota\n",
    "\n",
    "## Общая задача\n",
    "\n",
    "По информации о первых 5 минут игры предсказать, какая из команд победит: Radiant или Dire?\n",
    "\n",
    "## Подход 1: градиентный бустинг \"в лоб\"\n",
    "\n",
    "Один из самых универсальных алгоритмов, изученных в нашем курсе, является градиентный бустинг. Он не очень требователен к данным, восстанавливает нелинейные зависимости, и хорошо работает на многих наборах данных, что и обуславливает его популярность. Вполне разумной мыслью будет попробовать именно его в первую очередь.\n",
    "\n",
    "### Задача 1\n",
    "**Задача**: считайте таблицу с признаками из файла `features.csv` с помощью кода, приведенного выше. Удалите признаки, связанные с итогами матча (они помечены в описании данных как отсутствующие в тестовой выборке)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Решение:\n",
    "Загрузим датафрейм с данными признаков для обучающей выборки. Проверим размерность датафрейма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97230, 108)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "features = pd.read_csv('./_features/features.csv', index_col='match_id')\n",
    "print features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим из обучающей выборки поля с данными о будущем (т.е. поля, отсутствующие в тестовой выбороке). Также проверим размерность выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97230, 102)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_remove = ['duration', 'radiant_win', 'tower_status_radiant', 'tower_status_dire',\n",
    "                    'barracks_status_radiant', 'barracks_status_dire']\n",
    "features_cut = features.drop(columns_to_remove, axis=1)\n",
    "features_cut.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 2\n",
    "**Задача**: Проверьте выборку на наличие пропусков с помощью функции `count()`, которая для каждого столбца показывает число заполненных значений. Много ли пропусков в данных? Запишите названия признаков, имеющих пропуски, и попробуйте для любых двух из них дать обоснование, почему их значения могут быть пропущены.\n",
    "\n",
    "#### Решение:\n",
    "Посчитаем количество заполненных значений для каждого столбца и выберем такое, которое меньше общего количества объектов (т.е. столбцы с пропусками в данных):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first_blood_time               77677\n",
       "first_blood_team               77677\n",
       "first_blood_player1            77677\n",
       "first_blood_player2            53243\n",
       "radiant_bottle_time            81539\n",
       "radiant_courier_time           96538\n",
       "radiant_flying_courier_time    69751\n",
       "radiant_first_ward_time        95394\n",
       "dire_bottle_time               81087\n",
       "dire_courier_time              96554\n",
       "dire_flying_courier_time       71132\n",
       "dire_first_ward_time           95404\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = features_cut.count()\n",
    "counts[counts < features_cut.shape[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из 102 столбцов пропуски имеют только 12. Незаполненными являются в среднем 17% записей в указанных 12 столбцах.\n",
    "\n",
    "Очевидно, что пропуски в полях `first_blood_time`, `first_blood_team`, `first_blood_player1` обусловлены тем, что в примерно 20% матчей первая кровь так и не случается в течение первых 5 минут матча. Кроме того, в 31% случаев пролития первой крови в течение первых 5 минут матча к этому событию причастен только один игрок. Поэтому поле `first_blood_player2` имеет 45% пропусков.\n",
    "\n",
    "Также очевидно, что пропуски в остальных полях также обусловлены той же причиной -- соответствующие события не случились в течение первых 5 минут матча."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 3\n",
    "**Задача**: Замените пропуски на нули с помощью функции `fillna()`. На самом деле этот способ является предпочтительным для логистической регрессии, поскольку он позволит пропущенному значению не вносить никакого вклада в предсказание. Для деревьев часто лучшим вариантом оказывается замена пропуска на очень большое или очень маленькое значение — в этом случае при построении разбиения вершины можно будет отправить объекты с пропусками в отдельную ветвь дерева. Также есть и другие подходы — например, замена пропуска на среднее значение признака. Мы не требуем этого в задании, но при желании попробуйте разные подходы к обработке пропусков и сравните их между собой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Решение:\n",
    "Заменим пропуски на нули и создадим датафрейм объектов-признаков `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = features_cut.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 4\n",
    "\n",
    "**Задача**: Какой столбец содержит целевую переменную? Запишите его название."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Решение:\n",
    "Целевой переменной является `radiant_win` со значениями:\n",
    "- 1, если победила команда Radiant;\n",
    "- 0, если победили Dire.\n",
    "\n",
    "Создадим целевую переменную `y` и назначим ей значения из обучающей выборки. Проверим основные статистики переменной `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    97230.000000\n",
       "mean         0.518503\n",
       "std          0.499660\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          1.000000\n",
       "75%          1.000000\n",
       "max          1.000000\n",
       "Name: radiant_win, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = features['radiant_win']\n",
    "y.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 5\n",
    "**Задача**: Забудем, что в выборке есть категориальные признаки, и попробуем обучить градиентный бустинг над деревьями на имеющейся матрице \"объекты-признаки\". Зафиксируйте генератор разбиений для кросс-валидации по 5 блокам (KFold), не забудьте перемешать при этом выборку (shuffle=True), поскольку данные в таблице отсортированы по времени, и без перемешивания можно столкнуться с нежелательными эффектами при оценивании качества. Оцените качество градиентного бустинга (GradientBoostingClassifier) с помощью данной кросс-валидации, попробуйте при этом разное количество деревьев (как минимум протестируйте следующие значения для количества деревьев: 10, 20, 30). Долго ли настраивались классификаторы? Достигнут ли оптимум на испытанных значениях параметра n_estimators, или же качество, скорее всего, продолжит расти при дальнейшем его увеличении?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Решение:\n",
    "\n",
    "Проведем кросс-валидацию классификатора по разным значениям числа деревьев в модели с помощью объекта `GridSearchCV` из библиотеки `sklearn.grid_search`. Для этого:\n",
    "- Инициализируем классификатор `GradientBoostingClassifier`;\n",
    "- Создадим генератор разбиений KFold на 5 подвыборок.\n",
    "- Инициализируем объект кросс-валидации `GridSearchCV` с метрикой качества `roc_auc`;\n",
    "- Проведем кросс-валидацию и замерим время её выполнения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время кросс-валидации по трём прогонам градиентного бустинга на 10, 20 и 30 деревьев:  0:02:33.564795\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# Инициализируем классификатор\n",
    "clf = GradientBoostingClassifier(random_state=123)\n",
    "\n",
    "# Зададим пространство параметров классификатора, по которым будем гонять кросс-валидацию\n",
    "parameters = [ {'n_estimators': [10, 20, 30]} ]\n",
    "\n",
    "# Создадим 5 разбиений обучающей выборки\n",
    "kf = KFold(n=y.size, n_folds=5, shuffle=True, random_state=123)\n",
    "\n",
    "# Инициализируем объект кросс-валидации\n",
    "cv = GridSearchCV(clf, parameters, scoring='roc_auc', cv=kf)\n",
    "\n",
    "# Запомним время начала кросс-валидации\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "# Проведем кросс-валидацию классификатора по пространству параметров\n",
    "cv.fit(X, y)\n",
    "\n",
    "# Замерим время выполнения кросс-валидации\n",
    "time = datetime.datetime.now() - start_time\n",
    "print 'Время кросс-валидации по трём прогонам градиентного бустинга на 10, 20 и 30 деревьев: ', time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество градиентного бустинга на 10, 20 и 30 деревьях:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.66468, std: 0.00408, params: {'n_estimators': 10},\n",
       " mean: 0.68214, std: 0.00354, params: {'n_estimators': 20},\n",
       " mean: 0.68873, std: 0.00315, params: {'n_estimators': 30}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Время кросс-валидации можно существенно сократить. Нет необходимости обучать классификатор три раза на 10, 20 и 30 деревьев, достаточно сделать это один раз и посчитать метрику качества на 10, 20 и 30-й итерации градиентного бустинга."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время кросс-валидации по одному прогону градиентного бустинга на 30 деревьев:  0:01:09.617191\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# Инициализируем переменные\n",
    "n_folds = 5\n",
    "n_trees = 30\n",
    "scores = np.zeros((n_trees, n_folds))\n",
    "kf_idx = 0\n",
    "\n",
    "# Создадим 5 разбиений обучающей выборки\n",
    "kf = KFold(n=y.size, n_folds=5, shuffle=True, random_state=123)\n",
    "\n",
    "# Запомним время начала кросс-валидации\n",
    "start_time2 = datetime.datetime.now()\n",
    "\n",
    "# Основной цикл кросс-валидации по разбиениям\n",
    "for train, test in kf:\n",
    "    clf2 = GradientBoostingClassifier(n_estimators=n_trees, random_state=123)\n",
    "    clf2.fit(X.iloc[train], y.iloc[train])\n",
    "    \n",
    "    for tree_idx, prediction in enumerate(clf2.staged_predict_proba(X.iloc[test])):\n",
    "        scores[tree_idx, kf_idx] = roc_auc_score(y.iloc[test], prediction[:, 1])\n",
    "        \n",
    "    kf_idx += 1\n",
    "\n",
    "# Посчитаем среднее значение метрики и стандартное отклоенние для каждой итерации градиентного бустинга\n",
    "mean_scores = np.mean(scores, axis=1)\n",
    "\n",
    "# Замерим время выполнения кросс-валидации\n",
    "time2 = datetime.datetime.now() - start_time2\n",
    "print 'Время кросс-валидации по одному прогону градиентного бустинга на 30 деревьев: ', time2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметим, что в этом случае кросс-валидация заняла вдвое меньше времени. Посмотрим на средние значения метрики `roc_auc` для каждой итерации градиентного бустинга от 1 до 30 деревьев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of trees \tauc_roc\n",
      "1 \t\t0.593462255842\n",
      "2 \t\t0.611280794572\n",
      "3 \t\t0.619445710537\n",
      "4 \t\t0.625019061694\n",
      "5 \t\t0.635533438649\n",
      "6 \t\t0.644802324211\n",
      "7 \t\t0.651661229359\n",
      "8 \t\t0.655566590643\n",
      "9 \t\t0.6608590146\n",
      "10 \t\t0.664680547488\n",
      "11 \t\t0.668193676802\n",
      "12 \t\t0.67064813831\n",
      "13 \t\t0.672562795663\n",
      "14 \t\t0.673497366632\n",
      "15 \t\t0.675368279238\n",
      "16 \t\t0.676630746987\n",
      "17 \t\t0.677982772506\n",
      "18 \t\t0.679635428941\n",
      "19 \t\t0.680774183051\n",
      "20 \t\t0.68213730191\n",
      "21 \t\t0.682579261409\n",
      "22 \t\t0.683662362131\n",
      "23 \t\t0.684472788585\n",
      "24 \t\t0.685104989144\n",
      "25 \t\t0.685702146618\n",
      "26 \t\t0.686341993545\n",
      "27 \t\t0.686899109165\n",
      "28 \t\t0.687722666807\n",
      "29 \t\t0.688321442359\n",
      "30 \t\t0.688734147533\n"
     ]
    }
   ],
   "source": [
    "print 'no. of trees', '\\t', 'auc_roc'\n",
    "for idx, score in enumerate(mean_scores):\n",
    "    print idx+1, '\\t\\t', score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы получили такие же значения качество классификатора, как и в первом случае. Однако во втором случае оценка метрики качества более полная и дает представление о степени роста числа классификатора с увеличением количества деревьев. Мы можем ожидать, что при 30 и более деревьях значение метрики будет меняться в третьем и последующих знаках после запятой. Если последний показатель качества приемлем с точностью порядка 0.1%, то дальнейшее увеличение числа деревьев нецелесообразно.\n",
    "\n",
    "Ускорить обучение классификатора на базе градиентного бустинга можно следующим образом:\n",
    "- увеличить шаг антиградиентного спуска `learning_rate` (по умолчанию он равняется 0.1);\n",
    "- уменьшить максимальную глубину деревьев `max_depth`;\n",
    "- уменьшить количество признаков, учитываемых при разбиении дерева, `max_features`;\n",
    "- уменьшить количество объектов обучающей выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подход 2: логистическая регрессия\n",
    "\n",
    "Линейные методы работают гораздо быстрее композиций деревьев, поэтому кажется разумным воспользоваться именно ими для ускорения анализа данных. Одним из наиболее распространенных методов для классификации является логистическая регрессия.\n",
    "\n",
    "**Важно:** не забывайте, что линейные алгоритмы чувствительны к масштабу признаков! Может пригодиться sklearn.preprocessing.StandartScaler.\n",
    "\n",
    "### Шаг 1\n",
    "\n",
    "**Задача**: Оцените качество логистической регрессии (sklearn.linear_model.LogisticRegression с L2-регуляризацией) с помощью кросс-валидации по той же схеме, которая использовалась для градиентного бустинга. Подберите при этом лучший параметр регуляризации (C). Какое наилучшее качество у вас получилось? Как оно соотносится с качеством градиентного бустинга? Чем вы можете объяснить эту разницу? Быстрее ли работает логистическая регрессия по сравнению с градиентным бустингом?\n",
    "\n",
    "#### Решение:\n",
    "Приведем значения признаков к единому масштабу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "# Transform to pandas dataframe similar to initial dataframe X\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns, index=X.index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем кросс-валидацию классификатора `LogisticRegression` по разным значениям параметра регуляризации с помощью объекта GridSearchCV из библиотеки sklearn.grid_search. По умолчанию, модель `LogisticRegression` использует регуляризатор L2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время кросс-валидации по одному значению параметра регуляризации:  0:00:11.600744\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "lr = LogisticRegression(random_state=123)\n",
    "parameters_lr = [ {'C': [0.0001, 0.0003, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1]} ]\n",
    "kf = KFold(n=y.size, n_folds=5, shuffle=True, random_state=123)\n",
    "cv_lr = GridSearchCV(lr, parameters_lr, scoring='roc_auc', cv=kf)\n",
    "\n",
    "start_time3 = datetime.datetime.now()\n",
    "cv_lr.fit(X_scaled, y)\n",
    "time3 = datetime.datetime.now() - start_time3\n",
    "\n",
    "print 'Время кросс-валидации по одному значению параметра регуляризации: ', time3 / len(parameters_lr[0]['C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отметим, что время обучения классификатора в случае логистичекой регрессии существенно меньше времени обучения методом градиентного бустинга.\n",
    "\n",
    "Посмотрим на качество линейного классификатора при разных значениях параметра регуляризации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.71124, std: 0.00261, params: {'C': 0.0001},\n",
       " mean: 0.71499, std: 0.00274, params: {'C': 0.0003},\n",
       " mean: 0.71620, std: 0.00281, params: {'C': 0.001},\n",
       " mean: 0.71636, std: 0.00285, params: {'C': 0.003},\n",
       " mean: 0.71634, std: 0.00287, params: {'C': 0.01},\n",
       " mean: 0.71632, std: 0.00288, params: {'C': 0.03},\n",
       " mean: 0.71631, std: 0.00288, params: {'C': 0.1},\n",
       " mean: 0.71630, std: 0.00288, params: {'C': 0.3},\n",
       " mean: 0.71630, std: 0.00288, params: {'C': 1}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_lr.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучшим оказалось следующее решение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C parameter:\t{'C': 0.003} \n",
      "Best ROC-AUC score:\t0.716360904281\n"
     ]
    }
   ],
   "source": [
    "print 'Best C parameter:\\t', cv_lr.best_params_, '\\n', 'Best ROC-AUC score:\\t', cv_lr.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество линейного классификатора оказалось немного лучше, 0.72 против 0.69 в случае градиентного бустинга. Вероятней всего, модель градиентного бустинга сильно переобучается на заданной выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 2\n",
    "**Задача**: Среди признаков в выборке есть категориальные, которые мы использовали как числовые, что вряд ли является хорошей идеей. Категориальных признаков в этой задаче одиннадцать: lobby_type и r1_hero, r2_hero, ..., r5_hero, d1_hero, d2_hero, ..., d5_hero. Уберите их из выборки, и проведите кросс-валидацию для логистической регрессии на новой выборке с подбором лучшего параметра регуляризации. Изменилось ли качество? Чем вы можете это объяснить?\n",
    "\n",
    "#### Решение:\n",
    "\n",
    "Подготовим массив из имен категориальных признаков, которые необходимо удалить из выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['r1_hero',\n",
       " 'r2_hero',\n",
       " 'r3_hero',\n",
       " 'r4_hero',\n",
       " 'r5_hero',\n",
       " 'd1_hero',\n",
       " 'd2_hero',\n",
       " 'd3_hero',\n",
       " 'd4_hero',\n",
       " 'd5_hero',\n",
       " 'lobby_type']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_list = [x for x in X_scaled.columns if '_hero' in x]\n",
    "drop_list.append('lobby_type')\n",
    "drop_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим категориальные признаки из выборки и повторим кросс-валидацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.71125, std: 0.00258, params: {'C': 0.0001},\n",
       " mean: 0.71503, std: 0.00271, params: {'C': 0.0003},\n",
       " mean: 0.71625, std: 0.00278, params: {'C': 0.001},\n",
       " mean: 0.71642, std: 0.00282, params: {'C': 0.003},\n",
       " mean: 0.71640, std: 0.00284, params: {'C': 0.01},\n",
       " mean: 0.71638, std: 0.00285, params: {'C': 0.03},\n",
       " mean: 0.71637, std: 0.00285, params: {'C': 0.1},\n",
       " mean: 0.71636, std: 0.00285, params: {'C': 0.3},\n",
       " mean: 0.71636, std: 0.00285, params: {'C': 1}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_wo_category = X_scaled.drop(drop_list, axis=1)\n",
    "\n",
    "lr = LogisticRegression(random_state=123)\n",
    "parameters_lr = [ {'C': [0.0001, 0.0003, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1]} ]\n",
    "kf = KFold(n=y.size, n_folds=5, shuffle=True, random_state=123)\n",
    "cv_lr_wo_category = GridSearchCV(lr, parameters_lr, scoring='roc_auc', cv=kf)\n",
    "\n",
    "cv_lr_wo_category.fit(X_wo_category, y)\n",
    "cv_lr_wo_category.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C parameter:\t{'C': 0.003} \n",
      "Best ROC-AUC score:\t0.716419475043\n"
     ]
    }
   ],
   "source": [
    "print 'Best C parameter:\\t', cv_lr_wo_category.best_params_, '\\n', 'Best ROC-AUC score:\\t', cv_lr_wo_category.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что после удаления категориальных признаков качество классификатора осталось прежним (с точностью до 4 знака). Это может означать то, что либо данные признаки не несут никакой полезной информации для классификатора, либо полезная информация в них есть, но признаки необходимо преобразовать, создав фиктивные (dummy) переменные для каждой категории."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 3\n",
    "**Задача**: На предыдущем шаге мы исключили из выборки признаки rM_hero и dM_hero, которые показывают, какие именно герои играли за каждую команду. Это важные признаки — герои имеют разные характеристики, и некоторые из них выигрывают чаще, чем другие. Выясните из данных, сколько различных идентификаторов героев существует в данной игре (вам может пригодиться фукнция unique или value_counts)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Решение:\n",
    "Посчитаем количество уникальных героев:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n"
     ]
    }
   ],
   "source": [
    "hero_feature_names = [x for x in X.columns if '_hero' in x]\n",
    "hero_features = X[hero_feature_names]\n",
    "hero_id = np.unique(hero_features)\n",
    "hero_id_count = hero_id.size\n",
    "print hero_id_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также посчитаем максимальное значкение ID героев. Это нам понадобится на следующем шаге."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n"
     ]
    }
   ],
   "source": [
    "hero_feature_names = [x for x in X.columns if '_hero' in x]\n",
    "hero_features = X[hero_feature_names]\n",
    "hero_id = np.unique(hero_features)\n",
    "hero_id_max = hero_id.max()\n",
    "print hero_id_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 4\n",
    "**Задача**: Воспользуемся подходом \"мешок слов\" для кодирования информации о героях. Пусть всего в игре имеет N различных героев. Сформируем N признаков, при этом i-й будет равен нулю, если i-й герой не участвовал в матче; единице, если i-й герой играл за команду Radiant; минус единице, если i-й герой играл за команду Dire. Ниже вы можете найти код, который выполняет данной преобразование. Добавьте полученные признаки к числовым, которые вы использовали во втором пункте данного этапа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Решение:\n",
    "Предоставленный код не согласуется с его описанием. Судя по предоставленному коду, массив `X_pick` должен иметь вторую размерность, равную максимальному значению ID героя, а не количеству уникальных ID героев, как это указано в условии задачи. Создадим мешок слов с учетом этого замечания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_pick = np.zeros((X_scaled.shape[0], hero_id_max))\n",
    "\n",
    "for i, match_id in enumerate(X_scaled.index):\n",
    "    for p in xrange(5):\n",
    "        X_pick[i, X.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, X.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим полученные признаки `X_pick` к числовым признакам. Проверим размерность полученного массива. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97230, 203)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bag_of_words = np.hstack((X_wo_category.as_matrix(), X_pick))\n",
    "X_bag_of_words.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 5\n",
    "**Задача**: Проведите кросс-валидацию для логистической регрессии на новой выборке с подбором лучшего параметра регуляризации. Какое получилось качество? Улучшилось ли оно? Чем вы можете это объяснить?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Решение:\n",
    "Повторим кросс-валидацию для признаков с мешком слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.72496, std: 0.00291, params: {'C': 0.0001},\n",
       " mean: 0.73702, std: 0.00328, params: {'C': 0.0003},\n",
       " mean: 0.74618, std: 0.00363, params: {'C': 0.001},\n",
       " mean: 0.75019, std: 0.00377, params: {'C': 0.003},\n",
       " mean: 0.75153, std: 0.00377, params: {'C': 0.01},\n",
       " mean: 0.75173, std: 0.00374, params: {'C': 0.03},\n",
       " mean: 0.75174, std: 0.00372, params: {'C': 0.1},\n",
       " mean: 0.75173, std: 0.00372, params: {'C': 0.3},\n",
       " mean: 0.75173, std: 0.00372, params: {'C': 1}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty='l2')\n",
    "parameters_lr = [ {'C': [0.0001, 0.0003, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1]} ]\n",
    "kf = KFold(n=y.size, n_folds=5, shuffle=True, random_state=123)\n",
    "\n",
    "cv_lr_bag_of_words = GridSearchCV(lr, parameters_lr, scoring='roc_auc', cv=kf)\n",
    "cv_lr_bag_of_words.fit(X_bag_of_words, y)\n",
    "cv_lr_bag_of_words.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C parameter:\t{'C': 0.1} \n",
      "Best ROC-AUC score:\t0.751743954674\n"
     ]
    }
   ],
   "source": [
    "print 'Best C parameter:\\t', cv_lr_bag_of_words.best_params_, '\\n', 'Best ROC-AUC score:\\t', cv_lr_bag_of_words.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество классификатора с учетом мешка слов улучшилось до 0.75 по сравнению 0.72 в случае, когда мы не учитывали категориальные признаки. Это объясняется тем, что расширив пространство признаков дополнительными измерениями, по одному на каждое значение категориального признака, объекты выборки лучше разделились на два класса, и, соответственно, классификатор смог построить лучшую разделяющую гиперплоскость."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 6\n",
    "**Задача**: Постройте предсказания вероятностей победы команды Radiant для тестовой выборки с помощью лучшей из изученных моделей (лучшей с точки зрения AUC-ROC на кросс-валидации). Убедитесь, что предсказанные вероятности адекватные — находятся на отрезке [0, 1], не совпадают между собой (т.е. что модель не получилась константной).\n",
    "\n",
    "#### Решение:\n",
    "##### 1. Загрузка тестовой выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17177, 102)\n"
     ]
    }
   ],
   "source": [
    "features_test = pd.read_csv('./raw-data/features_test.csv', index_col='match_id')\n",
    "print features_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Преобразование данных тестовой выборки\n",
    "Произведем все преобразования данных, которые мы делали при обучении модели:\n",
    "- Заменим пропуски на нули."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = features_test.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Проведем масштабирование данных тестовой выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_scaled = scaler.transform(X_test)\n",
    "# Transform to pandas dataframe\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Преобразуем категориальные признаки методом \"мешка слов\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17177, 203)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled_wo_category = X_test_scaled.drop(drop_list, axis=1)\n",
    "\n",
    "X_test_pick = np.zeros((X_test.shape[0], hero_id_max))\n",
    "\n",
    "for i, match_id in enumerate(X_test.index):\n",
    "    for p in xrange(5):\n",
    "        X_pick[i, X_test.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, X_test.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "        \n",
    "X_test_bag_of_words = np.hstack((X_test_scaled_wo_category.as_matrix(), X_test_pick))\n",
    "X_test_bag_of_words.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Предсказание вероятности\n",
    "Расчитаем вероятность победы команды Radiant на тестовых данных с помощью лучшей модели логистической регрессии с \"мешком слов\" и с праметром регуляризации 0.1. Убедимся, что результат является осмысленным -- посмотрим основные статистики массива предсказаний вероятности победы Radiant и построим гисторграмму распределения этой вероятности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    17177.000000\n",
       "mean         0.515912\n",
       "std          0.214219\n",
       "min          0.005686\n",
       "25%          0.352662\n",
       "50%          0.520253\n",
       "75%          0.681991\n",
       "max          0.994058\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = cv_lr_bag_of_words.predict_proba(X_test_bag_of_words)[:, 1]\n",
    "\n",
    "# Convert prediction array into pandas Series\n",
    "prediction = pd.Series(prediction)\n",
    "\n",
    "# Print prediction statistics\n",
    "prediction.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEACAYAAAC+gnFaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nddz/B1GxfQfA5YP1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117311b10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist(prediction, 20)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
